{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Modules.NewTwitterReader import NewTwitterCorpusReader\n",
    "from Modules.TwitterDatabase import TwitterDatabase\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "from Modules.models import *\n",
    "from Modules.RedditScore.redditscore.tokenizer import CrazyTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOC_PATTERN = r'HPC_Data/streamed_[0-3][0-9]_[0-1][0-9]_[0-9][0-9][0-9][0-9]_[0-9][0-9]_[0-9][0-9]_[0-9][0-9]\\.json\\.gz$'\n",
    "DOC_PATTERN = r'HPC_Data/streamed_01_[0-1][0-9]_[0-9][0-9][0-9][0-9]_[0-9][0-9]_[0-9][0-9]_[0-9][0-9]\\.json\\.gz$'\n",
    "CAT_PATTERN = r'.*HPC_Data.*'\n",
    "# CAT_PATTERN = r'[0-2][0-9][0-9][0-9]-[0-3][0-9]-[0-1][0-9]'\n",
    "root = r\"../Twitter-Data\"\n",
    "corpus = NewTwitterCorpusReader(root = root, fileids = DOC_PATTERN, cat_pattern = CAT_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 0\n",
    "# for i in corpus.full_text_tweets(fileids = [\"HPC_Data/streamed_01_04_2020_08_55_32.json.gz\"]):\n",
    "#     if n > 20:\n",
    "#         break\n",
    "#     n+=1\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = \"postgres+psycopg2://bogdanowicz:urbandata@localhost:5432/twitter\"\n",
    "database = TwitterDatabase(corpus, database_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Building Tables first\n",
    "engine = create_engine(database_url)\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updating = database.update_database(categories = CAT_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(updating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code runs without issues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = pd.read_sql(\"location\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = \"postgres+psycopg2://bogdanowicz:urbandata@localhost:5432/twitter\"\n",
    "engine = create_engine(database_url)\n",
    "tweet = pd.read_sql(\"tweet\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cor_text = []\n",
    "for index, row in tweet.iterrows():\n",
    "    match = re.search(r'(\\bcov\\w+\\b \\b\\w+\\b)', row[\"full_text\"].lower())\n",
    "    if match:\n",
    "        cor_text.append(match.group(0))\n",
    "    match = re.search(r'(\\bcor\\w+\\b \\b\\w+\\b)', row[\"full_text\"].lower())\n",
    "    if match:\n",
    "        cor_text.append(match.group(0))\n",
    "    match = re.search(r'(\\bsars\\w+\\b \\b\\w+\\b)', row[\"full_text\"].lower())\n",
    "    if match:\n",
    "        cor_text.append(match.group(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rul0 = re.compile(r\"(\\bcov19\\b)|(\\bcov2019\\b)|(\\bcovid2019\\b)|(\\bcov2\\b)|(\\bcov-2\\b)|(\\bcovid\\b \\b19\\b)|(\\bcovid\\b \\b19\\b\\D)|(\\bcovid19\\b)|(\\bcovid19\\b)|(\\bcovid-19\\b)|(\\bcovidー19\\b)|(\\bcovid_19\\b)|(\\bcovid\\b)\")\n",
    "# rul0 = re.compile(r\".*(cov19).*|.*(cov2019).*|.*(covid2019).*|.*(cov2).*|.*(cov-2).*|.*(covid 19).*|.*(covid19).*|.*(covid19).*|.*(covid-19).*|.*(covidー19).*|.*(covid_19).*|.*(covid).*\")\n",
    "rul0 = re.compile(r\"\\bcov19\\b|\\bcov2019\\b|\\bcovid2019\\b|\\bcov2\\b|\\bcov-2\\b|\\bcovid\\b \\b19\\b|\\bcovid\\b \\b19\\b\\D|\\bcovid19\\b|\\bcovid19\\b|\\bcovid-19\\b|\\bcovidー19\\b|\\bcovid_19\\b|\\bcovid\\b\")\n",
    "# rul0 = re.compile(r\"\\bcovid\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul0.search(\"the covid epidemic has been a tragedy for all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = len(set(cor_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATTERNS = [\n",
    "#     ('corona',re.compile(r\"(\\bcorona-virus\\b)|(\\bcorona\\b \\bvirus\\b)|(\\bcorona\\b)|(\\bcovid\\b)\"),'coronavirus'),\n",
    "#     ('covid',re.compile(r\"(\\bcov19\\b)|(\\bcov2019\\b)|(\\bcovid2019\\b)|(\\bcov2\\b)|(\\bcov-2\\b)|(\\bcovid\\b \\b19\\b)|(\\bcovid\\b \\b19\\b\\D)|(\\bcovid19\\b)|(\\bcovid19\\b)|(\\bcovid-19\\b)|(\\bcovidー19\\b)|(\\bcovid_19\\b)|(\\bcovid\\b)|(\\bcorona\\b)\"),'coronavirus'),\n",
    "#     ('sars',re.compile(r\"(\\bsarscov2\\b)|(\\bsarscov-2\\b)|(\\bsars-cov-2\\b)|(\\bsars-cov\\b)|(\\bsarscov\\b)\"),'coronavirus')\n",
    "# ]\n",
    "PATTERNS = [\n",
    "    ('group1',re.compile(r\"\\bcorona-virus\\b|\\bcorona\\b \\bvirus\\b|\\bcorona\\b\"),\"coronavirus\"),\n",
    "    ('group2',re.compile(r\"\\bcov19\\b|\\bcov2019\\b|\\bcovid2019\\b|\\bcov2\\b|\\bcov-2\\b|\\bcovid\\b \\b19\\b|\\bcovid\\b \\b19\\b\\D|\\bcovid19\\b|\\bcovid19\\b|\\bcovid-19\\b|\\bcovidー19\\b|\\bcovid_19\\b|\\bcovid\\b\"),\"coronavirus\"),\n",
    "    ('group3',re.compile(r\"\\bsarscov2\\b|\\bsarscov-2\\b|\\bsars-cov-2\\b|\\bsars-cov\\b|\\bsarscov\\b\"),\"coronavirus\")\n",
    "]\n",
    "\n",
    "# PATTERNS = [\n",
    "#     ('group1',re.compile(r\"\\bcorona-virus\\b|\\bcorona\\b|\\bcovid\\b\"),'coronavirus'),\n",
    "#     ('rule1',re.compile(r\"\\bcorona\\b \\bvirus\\b\"),'coronavirus'),\n",
    "#     ('group2',re.compile(r\"\\bcov19\\b|\\bcov2019\\b|\\bcovid2019\\b|\\bcov2\\b|\\bcov-2\\b|\\bcovid\\b \\b19\\b|\\bcovid\\b \\b19\\b\\D|\\bcovid19\\b|\\bcovid19\\b|\\bcovid-19\\b|\\bcovidー19\\b|\\bcovid_19\\b|\\bcovid\\b|\\bcorona\\b\"),'coronavirus'),\n",
    "#     ('group3',re.compile(r\"\\bsarscov2\\b|\\bsarscov-2\\b|\\bsars-cov-2\\b|\\bsars-cov\\b|\\bsarscov\\b\"),'coronavirus')\n",
    "# ]\n",
    "\n",
    "#     ('rule1',re.compile(r\"corona virus\"),'coronavirus'),\n",
    "#     ('rule2',re.compile(r\"corona-virus\"),'coronavirus'),\n",
    "#     ('rule3',re.compile(r\"covid\"),'coronavirus'),\n",
    "#     ('rule4',re.compile(r\"covid19\"),'coronavirus'),\n",
    "#     ('rule5',re.compile(r\"covid-19\"),'coronavirus'),\n",
    "#     ('rule6',re.compile(r\"covid 19\"),'coronavirus'),\n",
    "#     ('rule7',re.compile(r\"covid_19\"),'coronavirus'),\n",
    "#     ('rule8',re.compile(r\"cov2\"),'coronavirus'),\n",
    "#     ('rule9',re.compile(r\"cov-2\"),'coronavirus'),\n",
    "#     ('rule10',re.compile(r\"sarscov2\"),'coronavirus'),\n",
    "#     ('rule11',re.compile(r\"sarscov-2\"),'coronavirus'),\n",
    "#     ('rule12',re.compile(r\"sars-cov-2\"),'coronavirus'),\n",
    "#     ('rule13',re.compile(r\"sars-cov\"),'coronavirus'),\n",
    "#     ('rule14',re.compile(r\"sarscov\"),'coronavirus'),\n",
    "#     ('rule15',re.compile(r\"cov19\"),'coronavirus'),\n",
    "#     ('rule16',re.compile(r\"cov2019\"),'coronavirus'),\n",
    "#     ('rule17',re.compile(r\"covid2019\"),'coronavirus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CrazyTokenizer(extra_patterns = PATTERNS, lowercase = True, normalize = 3, ignore_quotes = False,\n",
    "                            ignore_stopwords = True, stem = \"lemm\", remove_punct = True,\n",
    "                            remove_breaks = True, decontract = True, hashtags = \"split\",\n",
    "                            twitter_handles = 'split', urls = False)\n",
    "tokenized = []\n",
    "for index, row in tweet.iterrows():\n",
    "    tokenized.append(tokenizer.tokenize(row[\"full_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_to_check = [\" \".join(i) for i in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text, cor_matches, cov_matches, sars_matches = [], [], [], []\n",
    "countcov = 0\n",
    "countcor = 0\n",
    "countsars = 0\n",
    "for tw in tweets_to_check:\n",
    "    match = re.search(r'(\\bcoronavirus\\b)', tw)\n",
    "    match1 = re.search(r'(\\bcov\\w+\\b \\b\\w+\\b)', tw)\n",
    "    match2 = re.search(r'(\\bsars\\w+\\b \\b\\w+\\b)', tw)\n",
    "    if match:\n",
    "        token_text.append(match.group(0))\n",
    "        countcor += 1\n",
    "        cor_matches.append(tw)\n",
    "    elif match1:\n",
    "        token_text.append(match1.group(0))\n",
    "        countcov += 1\n",
    "        cov_matches.append(match1.group(0))\n",
    "    elif match2:\n",
    "        token_text.append(match2.group(0))\n",
    "        countsars += 1\n",
    "        sars_matches.append(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"countcov: \", countcov)\n",
    "print(\"countcor: \", countcor)\n",
    "print(\"countsars: \", countsars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(cor_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coronavirus\n",
    "#covid19\n",
    "#corona\n",
    "#corona virus\n",
    "#covid-19\n",
    "#covid 19\n",
    "#covid\n",
    "#cov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.at[16131, \"full_text\"]\n",
    "# tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.at[16132, \"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.int64(1245028040595460099)\n",
    "tweet[tweet[\"id\"] == x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet1 = tweet.astype(object).replace(np.nan, 'None')\n",
    "n = 0\n",
    "full = []\n",
    "for index, row in tweet1.iterrows():\n",
    "    if row[\"quote_id\"]!=\"None\" and n < 20:\n",
    "#         n+=1\n",
    "        full.append(row[\"full_text\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet1 = tweet.astype(object).replace(np.nan, 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet1[tweet1[\"retweet_id\"] != \"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet1.retweet_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tweet1[tweet1[\"retweet_id\"] != \"None\"]\n",
    "temp[temp.quote_id == temp.retweet_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweet[tweet[\"id\"] == 1244812675055587334].retweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.int64(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet[tweet[\"id\"] == x].full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.int64(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet[tweet[\"id\"] == y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-urban",
   "language": "python",
   "name": "venv-urban"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
